[
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "spatInfer Tutorial",
    "section": "",
    "text": "The purpose of spatInfer is to estimate regressions that are robust to the long range trends and medium range autocorrelation that are a feature of spatial observations. Specifically, a spatial basis is added to the regression and standard errors are estimated using large clusters. A feature of spatInfer is its simple workflow, requiring a sequence of only four commands.\nThe four steps in estimating a spatial basis regression with large cluster inference are\nThe first step is to download spatInfer.\n# devtools::install_github(\"morganwkelly/spatInfer\")\nWe begin by loading the spatInfer library and the data frame called opportunity.\nlibrary(spatInfer)\nlibrary(modelsummary)\nlibrary(ggplot2)\nlibrary(tinytable)\n\ndata(opportunity)\nThe example we will use here is based on the second column of Table VI in Chetty et al’s examination of income mobility across US cities. This consists of the outcome, absolute upward mobility, the treatment of interest fraction of single mothers, and four other controls: fraction short commute, Gini bottom 99%, high school dropout rate, and social capital index. Observations for Alaska and Hawaii are omitted to allow meaningful spatial correlations to be estimated. The longitude and latitude of each observation are included in the data. These must be named X and Y."
  },
  {
    "objectID": "tutorial.html#choose-the-spatial-basis",
    "href": "tutorial.html#choose-the-spatial-basis",
    "title": "spatInfer Tutorial",
    "section": "1. Choose the Spatial Basis",
    "text": "1. Choose the Spatial Basis\nThe first step is to estimate the optimal spatial basis that best explains the outcome variable. The spatial basis serves both to remove long range structure from the data (acting like a systematic version of the 49 state dummies included in the original regression) and to improve inference by allowing smaller clusters of residuals.\nWe apply the simplest basis possible: a k \\times k tensor of linear b-splines and, to minimize the loss of degrees of freedom, we select the first p principal components of the tensor. The first command `optimal_basis` chooses the combination of k and p that minimizes a Bayes Information Criterion. To make the diagram legible, select the maximum basis degree that you want to examine. As with most commands in R it starts with the regression formula and the name of the dataset. Here we will regress mobility on five variables used in Table VI of Chetty et al: the choice of right hand side variables does not matter at this stage.\nThe treatment of interest is placed as the first on the right hand side. If several are of concern the procedure can be repeated using each as the first entry.\n\noptimal_basis(mobility~single_mothers+short_commute+\n                gini+dropout_rate+social_cap+dropout_na,  opportunity,\n max_splines=7)\n\n\n\n\n\n\n\nFigure 1: Spline surface of social mobility.\n\n\n\n\n\nIt can be seen here that the optimal combination is the first 15 principal components of a 6x6 spline. It is notable that this very small number of spatial controls explains 60% of variability in the outcome, compared with 64% obtained by using the 49 state dummies of the original study. Knowing only the location of a place lets you make a decent guess about the likely degree of mobility there, without knowing anything about its other characteristics.\nIt is useful to plot the tensor surface of intergenerational mobility to see how geometrically simple it is. In The viewpoint is from the southeast of the US and the angular surface reflects the fact that a product of linear B-splines (series of overlapping triangles) is used.\n\nplot_basis(\n  mobility~single_mothers+short_commute+\n           gini+dropout_rate+social_cap+dropout_na,    opportunity,\nsplines=6, \nTitle=\"6x6 Tensor Surface of Mobility\"\n)\n\n\n\n\nSpline surface of social mobility."
  },
  {
    "objectID": "tutorial.html#run-placebo-test",
    "href": "tutorial.html#run-placebo-test",
    "title": "spatInfer Tutorial",
    "section": "2. Run Placebo Test",
    "text": "2. Run Placebo Test\nHaving chosen a spatial basis, we now need to choose an optimal number of clusters for the residuals. If there are too many, residuals will be correlated between clusters leading to inconsistent standard error estimates, whereas too few will result in unnecessarily wide confidence intervals. To choose the optimal number we use spatial noise placebos.\nThe placebos are constructed to have the same spatial structure as the treatment, here single mothers. First, the treatment is regressed on the spatial basis terms selected in Step 1. The spatial correlation between the detrended residuals is assumed to decay exponentially so that the correlation between two at distance h apart is \\rho \\exp (- \\theta / h).1 The parameters \\rho and \\theta are referred to as the structure and range of the correlation. Effective range is 2 \\theta: at this distance correlation equals 0.14. These parameters are estimated by maximum likelihood using the fields library and then used to estimate synthetic residuals which are added back onto the predicted treatment values to give the placebo values. The regression is run repeatedly with simulated placebos in place of the real treatment and the p-values of each simulation are recorded.\nThese placebo p-values give us two useful things. The first is a placebo significance level of the treatment: how often does a placebo have a lower p-value (higher t-statistic) than the treatment.\nThe second is that the placebos provide a Monte Carlo simulation to evaluate the inference procedure used. If substantially more than 5% of placebo regressions are significant at 5% we can conclude that the standard error estimate is deficient.\nStandard errors are estimated using the large cluster procedure of Bester, Conley and Hansen, where observations are partitioned into c large clusters using k-medoids. The placebo Monte Carlos allow an optimal value of c to be picked.\nThe placebo test is implemented by the command `placebo`. Again this starts off with the formula and data, followed by the tensor degree and number of principal components just picked by optimal_basis, and then the number of simulations. In practice the simulations settle down rapidly and 1000 will give accurate results but you may want to start with around 200 which will quickly give you a good idea of how your data are behaving.2\n\nplbo=placebo(mobility~single_mothers+short_commute+gini+dropout_rate+social_cap+dropout_na,                                 opportunity,\n                  splines=6,\n                  pc_num=15,\n                  nSim=1000,\n                  max_clus = 7\n       )\n\nplacebo_table(plbo)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Adj\n                Clusters\n                Est p\n                Plac p\n                Plac 5%\n                CI Width\n                CI\n              \n        \n        Moran=15.69, Structure=0.96, Effective Range=0.05, R2=0.46.\nSplines=6, PCs=15.\nEstimated and placebo p values and proportion of placebo regressions significant at 5%, along\n                with confidence intervals. R2 gives the explanatory power of a regression of the treatment on the principal components.\n        \n                \n                  HC \n                  .\n                  0    \n                  0    \n                  0.13 \n                  0.28\n                  [-1.14, -0.86]\n                \n                \n                  BCH\n                  3\n                  0.075\n                  0.09 \n                  0.057\n                  2.49\n                  [-2.25, 0.25] \n                \n                \n                     \n                  4\n                  0.038\n                  0.058\n                  0.076\n                  1.8 \n                  [-1.9, -0.1]  \n                \n                \n                     \n                  5\n                  0.02 \n                  0.015\n                  0.062\n                  1.48\n                  [-1.74, -0.26]\n                \n                \n                     \n                  6\n                  0.012\n                  0.013\n                  0.06 \n                  1.33\n                  [-1.66, -0.34]\n                \n                \n                  BCH\n                  7\n                  0.003\n                  0.008\n                  0.08 \n                  1.01\n                  [-1.51, -0.49]\n                \n        \n      \n    \n\n\n\nPlacebo generates a table where the top row uses heteroskedasticity consistent standard errors: if spatial correlation in residuals turns out to be unimportant these are the ones to use. Below this are large cluster (Bester-Conley-Hansen) standard errors, starting with three and going up to six. The second column gives the estimated p-value of the treatment variable from a regression that includes spatial basis terms. As the number of clusters increases this will generally fall.\nThe next column gives the placebo p-value: the proportion of simulations where the placebo had a lower p-value than the real treatment.\nFollowing this, and highlighted in orange, is the percentage of simulations where the placebo is significant at 5%. If this is markedly higher than 5% it suggests that the inference method employed was inadequate. In practice a value in the range of 0.05 to 0.07 or 0.08 indicates satisfactory performance.\nThe next column gives the width of the confidence interval associated with each cluster and allows an informal size-power tradeoff: increasing the proportion above 5% to, say, 7% is desirable if it leads to a marked narrowing of the confidence interval. In this case here, 5 or 6 clusters give very similar values with 6% of simulations significant at 5% suggesting that these are reasonable numbers: by contrast 13% of HC simulations are significant. We will report regression results for both below. For six clusters the placebo p-value of 0.01 equals the regression estimate of 0.01 and the confidence interval for the parameter is [-1.66,-0.34].\nIt will sometimes happen that the proportion of placebos significant at 5% stays considerably above 5% regardless of the cluster number. In that case systematically increasing, or sometimes decreasing, the number of principal components num_pc by one or two will usually give a satisfactory placebo value.\nBelow the Table are a number of diagnostics and descriptive statistics. Most important is the Moran statistic, the Z-score of the null hypothesis that the correlation between each residual and its nearest neighbours is zero. We use 5 neighbours here: altering this does not alter the results materially.3\nIn deciding whether to use a familiar HC standard error or a large cluster one we have adopted the rule of thumb that if this has a low Moran statistic and a 5% placebo value close to 0.05 it should be used, given its tighter confidence intervals. Otherwise a BCH cluster below 0.08 is picked.\nBelow the Moran statistic are the spatial parameters. R2 gives the explanatory power of the regression of the treatment on the spatial basis variables, in this case 0.46. Next is the structure \\rho of the residuals and then the effective range (where correlation has fallen to 0.14) expressed as a fraction of the 95th percentile of distance between points.\nHere it can be seen that structure and effective range are 0.96 and 0.05 respectively. Finally the degree of the tensor and the number of principal components used to approximate the outcome are reported."
  },
  {
    "objectID": "tutorial.html#run-a-synthetic-outcome-test",
    "href": "tutorial.html#run-a-synthetic-outcome-test",
    "title": "spatInfer Tutorial",
    "section": "3. Run a Synthetic Outcome Test",
    "text": "3. Run a Synthetic Outcome Test\nFollowing the placebo test, the next step is to calculate the synthetic outcome p-value: Can we reject the null hypothesis that the outcome is trending spatial noise, and therefore independent of the treatment?\nAn important thing about the synthetic outcome test is that it can be computed in situations where there is a binary treatment so a placebo test cannot be estimated. In this case it is best to report the p-values for a range of cluster values from 3 to 5 or more to allow readers to judge the robustness of the results.\nWe assume that the outcome is generated as a quadratic in longitude and latitude. Noise is generated using maximum likelihood estimates of the residuals’ spatial parameters: here there is a structure of 0.88 and an effective range of 0.15.\n\nsynt_bch=synth(mobility~single_mothers+short_commute+gini+dropout_rate+social_cap+dropout_na,                                 opportunity,\n                  splines=6,\n                  pc_num=15,\n                  nSim=1000,\n                  max_clus = 7)\n\nsynth_table(synt_bch)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Adj\n                Clusters\n                Est p\n                Synth p\n                CI Width\n                CI\n              \n        \n        Moran=15.69, Structure=0.88, Effective Range=0.15, R2=0.43.\nN=693, Splines=6, PCs=15.\nEstimated and synthetic outcome p values for different cluster numbers.\n                R2 gives the explanatory power of a regression of the outcome on a quadratic in longitude and latitude.\n        \n                \n                  HC \n                  .\n                  0    \n                  0    \n                  0.28\n                  [-1.14, -0.86]\n                \n                \n                  BCH\n                  3\n                  0.075\n                  0.14 \n                  2.49\n                  [-2.25, 0.25] \n                \n                \n                     \n                  4\n                  0.038\n                  0.059\n                  1.8 \n                  [-1.9, -0.1]  \n                \n                \n                     \n                  5\n                  0.02 \n                  0.041\n                  1.48\n                  [-1.74, -0.26]\n                \n                \n                     \n                  6\n                  0.012\n                  0.041\n                  1.33\n                  [-1.66, -0.34]\n                \n                \n                  BCH\n                  7\n                  0.003\n                  0.011\n                  1.01\n                  [-1.51, -0.49]\n                \n        \n      \n    \n\n\n\nFor the five or six clusters chosen by the placebo test, the synthetic outcome significance level is 0.04, somewhat higher than the placebo one."
  },
  {
    "objectID": "tutorial.html#estimate-the-spatial-basis-regression",
    "href": "tutorial.html#estimate-the-spatial-basis-regression",
    "title": "spatInfer Tutorial",
    "section": "4. Estimate the Spatial Basis Regression",
    "text": "4. Estimate the Spatial Basis Regression\nThe fact that the placebo and synthetic outcome significance levels closely match the regression one gives us considerable confidence in the reliability of the regression estimate. We therefore estimate a regression with 15 principal components of a 6x6 spline, and compute standard errors using both five and six k-medoids clusters.\nFor comparison we also include the original regression with state dummies and residuals clustered by state. The state dummies act as a spatial basis in this regression with 48 variables as opposed to the 15 used in the basis regressions.\nBecause t-statistics for BCH regressions are not readily interpretable given their low degrees of freedom (for instance, the 5% significance level for 5 clusters is 2.8), the Table reports confidence intervals and p-values.\n\nBasis_5=basis_regression(mobility~single_mothers+short_commute+gini+dropout_rate+social_cap+dropout_na, opportunity,\nsplines=6,pc_num=15,\nclusters=5)\n\nBasis_6=basis_regression(mobility~single_mothers+short_commute+gini+dropout_rate+social_cap+dropout_na, opportunity,\nsplines=6,pc_num=15,\nclusters=6)\n\nOriginal=fixest::feols(mobility~single_mothers+short_commute+gini+dropout_rate+social_cap+dropout_na+state_id, opportunity,\ncluster= ~state_id)\n\nmodelsummary(list(Clustered=Original, \n                 `Basis 5`=Basis_5,\n                 `Basis 6`=Basis_6),\nstatistic = c(\"conf.int\",\"p = {p.value}\"),\ncoef_omit = c(\"Intercept|PC*|dropout_na|state*\"), #omit basis and intercept\ngof_map = c(\"nobs\", \"r.squared\"),\nfmt=2,\nnotes=\"Clustered is a standard regression estimate without a spatial basis and clustered by state. Basis 5 and 6 use 11 principal components of a 6x6 linear b-spline basis, with 5 and 6 k-medoids clusters respectively.\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Clustered\n                Basis 5\n                Basis 6\n              \n        \n        Clustered is a standard regression estimate without a spatial basis and clustered by state. Basis 5 and 6 use 11 principal components of a 6x6 linear b-spline basis, with 5 and 6 k-medoids clusters respectively.\n        \n                \n                  single_mothers\n                  -0.49         \n                  -0.51         \n                  -0.51         \n                \n                \n                                \n                  [-0.64, -0.35]\n                  [-0.88, -0.13]\n                  [-0.84, -0.17]\n                \n                \n                                \n                  p = &lt;0.01     \n                  p = 0.02      \n                  p = 0.01      \n                \n                \n                  short_commute \n                  0.31          \n                  0.26          \n                  0.26          \n                \n                \n                                \n                  [0.25, 0.38]  \n                  [0.05, 0.46]  \n                  [0.10, 0.42]  \n                \n                \n                                \n                  p = &lt;0.01     \n                  p = 0.03      \n                  p = &lt;0.01     \n                \n                \n                  gini          \n                  0.01          \n                  0.00          \n                  0.00          \n                \n                \n                                \n                  [-0.06, 0.08] \n                  [-0.09, 0.08] \n                  [-0.06, 0.05] \n                \n                \n                                \n                  p = 0.70      \n                  p = 0.89      \n                  p = 0.84      \n                \n                \n                  dropout_rate  \n                  -0.10         \n                  -0.10         \n                  -0.10         \n                \n                \n                                \n                  [-0.17, -0.02]\n                  [-0.24, 0.05] \n                  [-0.20, 0.01] \n                \n                \n                                \n                  p = 0.01      \n                  p = 0.15      \n                  p = 0.07      \n                \n                \n                  social_cap    \n                  0.05          \n                  0.08          \n                  0.08          \n                \n                \n                                \n                  [-0.05, 0.15] \n                  [-0.09, 0.25] \n                  [-0.07, 0.23] \n                \n                \n                                \n                  p = 0.29      \n                  p = 0.26      \n                  p = 0.23      \n                \n                \n                  Num.Obs.      \n                  693           \n                  693           \n                  693           \n                \n                \n                  R2            \n                  0.877         \n                  0.842         \n                  0.842         \n                \n        \n      \n    \n\n\n\nNext we can plot confidence intervals for the regressions. It is evident that the confidence interval for single mothers has grown substantially wider, and that the effects of commuting distance and, especially, social capital have fallen considerably.\n\nmodelplot(list(Clustered=Original, \n                             `Basis 5`=Basis_5,\n                                `Basis 6`=Basis_6),\n                           coef_omit = c(\"Intercept|PC*|dropout_na|state*\")\n                           )+\n  geom_vline(xintercept=0,color=\"red\",linewidth=0.25,linetype=3)\n\n\n\n\n95% confidence intervals for clustered and spatial basis regressions."
  },
  {
    "objectID": "tutorial.html#im-inference",
    "href": "tutorial.html#im-inference",
    "title": "spatInfer Tutorial",
    "section": "IM Inference",
    "text": "IM Inference\nBesides BCH standard errors, there is another spatial inferential method based on large clusters due to Ibragimov and Mueller. This involves running the regression of interest on each cluster and collecting the estimated coefficients of the treatment \\hat{\\beta}_c for each cluster c. The p-value of a regression of these coefficients on a constant is conservative up to a value of 0.08. Once again the optimal number of clusters is chosen by the fraction of placebo regressions that are significant at 5%.\n\nplbo_im=placebo_im(mobility~single_mothers+short_commute+gini+dropout_rate+social_cap+dropout_na,                                 opportunity,\n                  splines=6,\n                  pc_num=15,\n                  nSim=1000,\n                  max_clus = 7\n                 )\nplacebo_table(plbo_im)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Adj\n                Clusters\n                Est p\n                Plac p\n                Plac 5%\n                CI Width\n                CI\n              \n        \n        Moran=15.69, Structure=0.96, Effective Range=0.05, R2=0.46.\nSplines=6, PCs=15.\nEstimated and placebo p values and proportion of placebo regressions significant at 5%, along\n                with confidence intervals. R2 gives the explanatory power of a regression of the treatment on the principal components.\n        \n                \n                  HC\n                  .\n                  0    \n                  0    \n                  0.13 \n                  0.28\n                  [-1.14, -0.86]\n                \n                \n                  IM\n                  3\n                  0.057\n                  0.053\n                  0.046\n                  2.14\n                  [-2.07, 0.07] \n                \n                \n                    \n                  4\n                  0.023\n                  0.024\n                  0.046\n                  1.48\n                  [-1.74, -0.26]\n                \n                \n                    \n                  5\n                  0.008\n                  0.004\n                  0.054\n                  1.13\n                  [-1.56, -0.44]\n                \n                \n                    \n                  6\n                  0.003\n                  0.002\n                  0.042\n                  0.93\n                  [-1.46, -0.54]\n                \n                \n                  IM\n                  7\n                  0.002\n                  0.002\n                  0.054\n                  0.93\n                  [-1.46, -0.54]\n                \n        \n      \n    \n\n\n\nIt can be seen that with five clusters, the proportion of placebo regressions significant at 5% is 0.05. The regression, placebo and synthetic outcome p values are 0.01, 0.004, and 0.01 respectively, not markedly different from BCH.\n\nsyn_im=synth_im(mobility~single_mothers+short_commute+gini+dropout_rate+social_cap+dropout_na,                                 opportunity,\n                  splines=6,\n                  pc_num=15,\n                  nSim=1000,\n                  max_clus = 7)\nsynth_table(syn_im)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Adj\n                Clusters\n                Est p\n                Synth p\n                CI Width\n                CI\n              \n        \n        Moran=15.69, Structure=0.88, Effective Range=0.15, R2=0.43.\nN=693, Splines=6, PCs=15.\nEstimated and synthetic outcome p values for different cluster numbers.\n                R2 gives the explanatory power of a regression of the outcome on a quadratic in longitude and latitude.\n        \n                \n                  HC\n                  .\n                  0    \n                  0    \n                  0.28\n                  [-1.14, -0.86]\n                \n                \n                  IM\n                  3\n                  0.057\n                  0.055\n                  2.14\n                  [-2.07, 0.07] \n                \n                \n                    \n                  4\n                  0.023\n                  0.022\n                  1.48\n                  [-1.74, -0.26]\n                \n                \n                    \n                  5\n                  0.008\n                  0.007\n                  1.13\n                  [-1.56, -0.44]\n                \n                \n                    \n                  6\n                  0.003\n                  0.002\n                  0.93\n                  [-1.46, -0.54]\n                \n                \n                  IM\n                  7\n                  0.002\n                  0.004\n                  0.93\n                  [-1.46, -0.54]\n                \n        \n      \n    \n\n\n\nGiven that the IM confidence interval is considerably wider than the BCH one ( [-1.56,-0.44] here, compared with [-0.88,-0.13]) as is usually the case, the similar p-values arise because its central value is far lower than the BCH one. If we repeat the exercise for the other variables, short commute again has similar p-values to BCH and a high but wide interval. The other three variables have wide intervals centred near zero.\n\nx &lt;- data.frame(\n  Var=c(\"single_mothers\",\"short_commute\",\"gini\" ,          \"dropout_rate\",\"short_commute\"),\n  reg=c(0.01,0.01,0.26,0.23,0.78),\n  placebo=c(0.00,0.01,0.21,0.21,0.80),\n  synth=c(0.01,0.02,0.29,0.23,0.77),\n  CI=c(\"[-1.56,-0.44]\",\"[0.33,1.67]\",\"[-3.14,1.14]\",\"[-2.98,0.98]\",\"[-8.52,10.52]\")\n)\n\ntt(x,caption=\"Regression, placebo, and synthetic p-values along with confidence intervals using IM inference.\")\n\n\n\n    \n\n    \n    \n      \n        \n        Regression, placebo, and synthetic p-values along with confidence intervals using IM inference.\n              \n                Var\n                reg\n                placebo\n                synth\n                CI\n              \n        \n        \n        \n                \n                  single_mothers\n                  0.01\n                  0.00\n                  0.01\n                  [-1.56,-0.44]\n                \n                \n                  short_commute \n                  0.01\n                  0.01\n                  0.02\n                  [0.33,1.67]  \n                \n                \n                  gini          \n                  0.26\n                  0.21\n                  0.29\n                  [-3.14,1.14] \n                \n                \n                  dropout_rate  \n                  0.23\n                  0.21\n                  0.23\n                  [-2.98,0.98] \n                \n                \n                  short_commute \n                  0.78\n                  0.80\n                  0.77\n                  [-8.52,10.52]"
  },
  {
    "objectID": "tutorial.html#footnotes",
    "href": "tutorial.html#footnotes",
    "title": "spatInfer Tutorial",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe exponential kernel is a special case of the Matern function with smoothness parameter of 0.5, and in principle the optimal smoothing parameter can be chosen by maximum likelihood. In practice this makes little difference: as smoothness increases the estimated range \\theta falls, leaving correlation more or less unchanged.↩︎\nThe placebo and synthetic outcome tests run in parallel by default. If you encounter computational problems you should set the option Parallel=FALSE in each command. For large datasets, estimating the necessary Cholesky decomposition of the correlation matrix and the k-medoids clusters can be time-consuming, and fast approximations can be used by setting k_medoids=FALSE and exact_cholesky=FALSE in the placebo command. The latter requires the BRISC package.↩︎\nSee Table 3 in Conley and Kelly.↩︎"
  }
]